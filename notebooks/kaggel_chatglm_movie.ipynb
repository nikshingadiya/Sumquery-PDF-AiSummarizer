{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from PyPDF2 import PdfReader\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "import openai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import ChatGLM\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default endpoint_url for a local deployed ChatGLM api server\n",
    "endpoint_url = \"https://f7ad-35-227-93-64.ngrok-free.app\"\n",
    "\n",
    "# direct access endpoint in a proxied environment\n",
    "# os.environ['NO_PROXY'] = '127.0.0.1'\n",
    "\n",
    "llm = ChatGLM(\n",
    "    endpoint_url=endpoint_url,\n",
    "    max_token=80000,\n",
    "    history=[],\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=extract_text_from_pdf(\"/home/nikhil/Documents/Github/Sumquery-PDF-AiSummarizer/trash/pacific-rim-2013.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text=\"\"\"Elon Reeve Musk (/ˈiːlɒn/ EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and chief technology officer of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$222 billion as of December 2023, according to the Bloomberg Billionaires Index, and $244 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.[5][6]\n",
    "\n",
    "# A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University. However, Musk dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal.\n",
    "\n",
    "# In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial intelligence company.\n",
    "\n",
    "# Musk has expressed views that have made him a polarizing figure.[7][8][9] He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation, transphobia[10][11][12] and antisemitic conspiracy theories.[7][13][14][15] His ownership of Twitter has been similarly controversial, including; laying off a large number of employees, an increase in hate speech and misinformation and disinformation on the website, as well as changes to Twitter Blue verification. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him for falsely tweeting that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the following text, extract and list down the important scenes:\n",
    "Also,please add some of descriptions\n",
    "---\n",
    "\n",
    "{text}\n",
    "\n",
    "---\n",
    "\n",
    "List of Scenes:\n",
    "1. Extracted Scene 1\n",
    "2. Extracted Scene 2\n",
    "3. Extracted Scene 3\n",
    "4. Extracted Scene 4\n",
    "5. Extracted Scene 5\n",
    "\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/Documents/Github/Sumquery-PDF-AiSummarizer/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "separator=\"\\n\",\n",
    "chunk_size=1000,\n",
    "chunk_overlap=200,\n",
    "length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "    \n",
    "# create docs\n",
    "docs = [Document(page_content=t) for t in chunks[:10]]\n",
    "\n",
    "\n",
    "# show summarize doc\n",
    "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "summarized_docs = chain.run(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary\")\n",
    "print(summarized_docs)\n",
    "wrapped_text = textwrap.wrap(summarized_docs, width=100)\n",
    "\n",
    "# Print the wrapped text\n",
    "for line in wrapped_text:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. \n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main themes of the Pacific Rim Lexicon are:\n",
      "\n",
      "1. The Jaeger universe and its various factions or factions.\n",
      "2. The use of advanced technology, including but not limited to:\n",
      "\t* Anteverse\n",
      "\t* BTB\n",
      "\t* conn-pod\n",
      "\t* COSDEC\n",
      "\t* drift\n",
      "\t* drivesuit\n",
      "\t* ghost-drift\n",
      "3. The concept of the Pons, a device for linking Jaeger crew members together.\n",
      "4. The term \"bruiser,\" which refers to a Jaeger gunner.\n",
      "5. The term \"BTB,\" which refers to brain-to-brain interface.\n",
      "6. The term \"conn-pod,\" which refers to the Jaeger's detachable cockpit module.\n",
      "7. The term \"COSDEC,\" which refers to the Pacific Rim Combined Special Defense Corp.\n",
      "8. The concept of drift, which refers to a shared vision among Jaeger crew members.\n",
      "9. The use of the \"drivesuit,\" which is the Jaeger/pilot interface suit designed to monitor vital signs and translate nerve signals to piloting input.\n",
      "10. The term \"ghost-drift,\" which refers to a kind of quasi-telepathic vision shared between parties with a pre-existing Pons connection.\n",
      "\n",
      "The main themes of these documents are:\n",
      "\n",
      "1. Virtual reality and telepresence: Several of the documents refer to headspace, virtual spaces, and remote controlled interactions within these virtual spaces.\n",
      "2. Stress, physical proximity, and sleep patterns: Several of the documents mention the triggers for Jaeger operators, including stress, physical proximity, and coinciding REM sleep patterns.\n",
      "3. Human-computer interfaces: Two documents mention the use of HUDs, while one document mentions the use of Kodiak, a specialized threat response mech.\n",
      "4. The Cosdec Defense College: One document mentions Kodiak as a student at the Cosdec Defense College.\n",
      "5. Operations and surveillance: Two documents mention Midway as a highly classified research facility for surveillance and operations.\n",
      "6. Life-like virtual beings: Two documents mention KJ, a hypothetical kaiju-like being.\n",
      "7. Command and dispatch: One document mentions LOCCENT, a short for Local Command Center.\n",
      "8. Military operations and tactics: The documents mention \"Game on! That sonuvabitch is down!\" and \"We got him!\" suggesting that there is a military operation going on.\n",
      "9. The destruction of a city: The document describes the destruction of the city of Shinagawa and the impact it had on the people and infrastructure.\n",
      "10. The fight for survival: The characters are described as being in the \"chaotic rubble\" and being \"pulled back\" from the scene of the attack. They are able to survive and are treating the wounded.\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
