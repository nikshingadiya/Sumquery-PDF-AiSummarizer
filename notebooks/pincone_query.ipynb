{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from llama_index import Document\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "from llama_index.vector_stores import PineconeVectorStore,MilvusVectorStore\n",
    "from PyPDF2 import PdfReader\n",
    "from llama_index import GPTVectorStoreIndex, StorageContext, ServiceContext\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import VectorStoreIndex, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PyPDF2 import PdfReader\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "import openai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import ChatGLM\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri=os.environ.get(\"uri\")\n",
    "token=os.environ.get(\"token\")\n",
    "collection_name=os.environ.get(\"MILVUS_COLLECTION_NAME\")\n",
    "dim=os.environ.get(\"VECTOR_DIMENSION\")\n",
    "vector_field=os.environ.get(\"VECTOR_FIELD\")\n",
    "doc_id_field=os.environ.get(\"DOC_ID_FIELD\")\n",
    "text_key=os.environ.get(\"TEXT_KEY\")\n",
    "pincone_env=os.environ.get(\"PINCONE_ENV\")\n",
    "pincone_key=os.environ.get(\"PINCONE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default endpoint_url for a local deployed ChatGLM api server\n",
    "# endpoint_url = \"https://5448-35-227-160-165.ngrok-free.app\"\n",
    "\n",
    "# # direct access endpoint in a proxied environment\n",
    "# # os.environ['NO_PROXY'] = '127.0.0.1'\n",
    "\n",
    "# llm = ChatGLM(\n",
    "#     endpoint_url=endpoint_url,\n",
    "#     max_token=80000,\n",
    "#     history=[],\n",
    "#     top_p=0.9,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/Documents/Github/Sumquery-PDF-AiSummarizer/venv/lib/python3.8/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pinecone\n",
    "\n",
    "\n",
    "\n",
    "# initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINCONE_KEY'),\n",
    "    environment=os.environ.get('PINCONE_ENV')\n",
    ")\n",
    "\n",
    "# create the index if it does not exist already\n",
    "index_name = 'llama-index-intro'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric='cosine'\n",
    "    )\n",
    "\n",
    "# connect to the index\n",
    "pinecone_index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_pinecone = PineconeVectorStore(pinecone_index=pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup our storage (vector db)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=pinecone_index\n",
    ")\n",
    "# setup the index/query process, ie the embedding model (and completion if used)\n",
    "embed_model = HuggingFaceEmbeddings()\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_vector_store(vector_store=vector_store_pinecone,service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"List the top 15 main scenes in sequence covering the entire script with brief descriptions in 50 words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Trudy and Max overpower a guard and free a prisoner from a cell.\n",
      "2. Another trooper appears, but Trudy takes him down while Max knocks out the first trooper.\n",
      "3. Trudy kisses Norm as he escapes from the cell.\n",
      "4. Jake grabs a sidearm from a fallen trooper and thanks Max and Trudy.\n",
      "5. Jake asks the group if it's time for a revolution.\n",
      "6. Grace expresses her freedom and Trudy taps Jake's fist.\n",
      "7. The group reaches a utility corridor and Jake pumps a chair while the others put on exopacks.\n",
      "8. Norm points out a herd of sturmbest, massive six-legged creatures.\n",
      "9. Hundreds of purple winged creatures take flight from a lake.\n",
      "10. The Samson flies over a waterfall, with Trudy performing daring maneuvers.\n",
      "11. Wainfleet encourages Chacon to \"get some\" during the flight.\n",
      "12. The Samson lands in a clearing, causing the fern-like grass to be flattened by the rotor-wash.\n",
      "13. Jake removes a massive door gun from its mount.\n",
      "14. The group prepares for the next scene or action.\n",
      "15. The script continues with further scenes and dialogue.\n"
     ]
    }
   ],
   "source": [
    "print(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
